{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab207b34-36c5-48b0-9de1-05a3f2fd5606",
   "metadata": {},
   "source": [
    "# Load Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db209457-0a45-4d18-8f79-f3dcbd1db0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random, os, gc, psutil\n",
    "import scanpy as sc\n",
    "import anndata as ann\n",
    "from scipy.stats import pearsonr as pr\n",
    "\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score,\n",
    "    mean_squared_error, average_precision_score,\n",
    "    precision_score, recall_score, precision_recall_curve as prc,\n",
    "    auc, silhouette_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# PyTorch Geometric\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import TransformerConv, GraphConv, GCNConv\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix, subgraph\n",
    "from torch_geometric.loader import NeighborLoader, RandomNodeLoader\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Collections\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66dadaf9-fea5-454b-a889-57c6a194701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "def set_random_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # if using CUDA\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seeds(42)\n",
    "# Check if GPU is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7421bd83-b3ed-47da-82e6-f2581d5669cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_usgae():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_gb = process.memory_info().rss / 1024**3  # in GB\n",
    "\n",
    "    print(f\"Current memory usage: {memory_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e031e-55ee-45af-bd32-59d44b0a5a89",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1b416-9b9f-441a-8955-a0d60fdb756d",
   "metadata": {},
   "source": [
    "Load data in an anndata object, here we load the processed atlas as an example, a classifier label is required in ad.obs as the metastasis label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db4746b-3937-4a80-a205-8f922123744f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 725643 × 2132\n",
       "    obs: 'Project_ID', 'Primary_or_Metastatic', 'Final_cancer_type', 'Final_histological_subtype', 'Final_molecular_subtype', 'Final_tissue', 'Final_sample_id', 'Final_patient_age', 'Final_patient_stage', 'Final_patient_treatment', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Final_histological_subtype_backup', 'Final_patient_age_backup', 'Final_tissue_backup', 'Final_patient_treatment_backup', 'Final_patient_stage_backup', 'Classifier_label'\n",
       "    var: 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'\n",
       "    uns: 'Final_cancer_type_colors', 'Final_histological_subtype_colors', 'Final_molecular_subtype_colors', 'Final_patient_stage_colors', 'Final_patient_treatment_colors', 'Final_tissue_colors', 'Primary_or_Metastatic_colors', 'Project_ID_colors', 'log1p', 'neighbors', 'pca', 'umap'\n",
       "    obsm: 'X_pca', 'X_pca_harmony', 'X_pca_harmony_Project_ID', 'X_pca_harmony_project_id', 'X_umap'\n",
       "    varm: 'PCs'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "ad = sc.read_h5ad('../Data/Cancer_cell_data/All_integrated.hallmark.harmony.h5ad')\n",
    "ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be6c220-707b-4255-963c-27755a93a1af",
   "metadata": {},
   "source": [
    "Here we created an extra column in ad.obs as the label to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad6c162-57f8-4663-940f-6a543efa6f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "Non_metastatic_local    328282\n",
      "Metastatic_distant      249125\n",
      "Metastatic_local        148236\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Map cancer type → its \"primary tissue\"\n",
    "primary_tissue_map = {\n",
    "    \"Breast Cancer\": \"Breast\",\n",
    "    \"Lung Cancer\": \"Lung\",\n",
    "    \"Ovarian Cancer\": \"Ovary\",\n",
    "    \"Colorectal Cancer\": \"Colon\"\n",
    "}\n",
    "\n",
    "# Initialize as primary\n",
    "ad.obs[\"source\"] = \"Non_metastatic_local\"\n",
    "\n",
    "\n",
    "# Loop through rows\n",
    "for idx, row in ad.obs.iterrows():\n",
    "    cancer_type = row[\"Final_cancer_type\"]\n",
    "    tissue = row[\"Final_tissue\"]\n",
    "\n",
    "    primary_site = primary_tissue_map.get(cancer_type, None)\n",
    "\n",
    "    if row[\"Primary_or_Metastatic\"] == \"Primary\":\n",
    "        ad.obs.at[idx, \"source\"] = \"Non_metastatic_local\"\n",
    "\n",
    "    else:  # Metastatic\n",
    "        if tissue == primary_site:\n",
    "            ad.obs.at[idx, \"source\"] = \"Metastatic_local\"\n",
    "        else:\n",
    "            ad.obs.at[idx, \"source\"] = \"Metastatic_distant\"\n",
    "\n",
    "# Summary:\n",
    "print(ad.obs[\"source\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3181a60e-ac7f-4877-88e0-bd6ee4e381a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 725643 cells\n",
      "Sampled: 72564 cells\n"
     ]
    }
   ],
   "source": [
    "# here we sample 10% of samples for an illustration\n",
    "\n",
    "n_cells = ad.n_obs\n",
    "sample_size = int(n_cells * 0.1)\n",
    "np.random.seed(42)  # for reproducibility\n",
    "sample_indices = np.random.choice(n_cells, size=sample_size, replace=False)\n",
    "ad_subset = ad[sample_indices, :]\n",
    "\n",
    "print(f\"Original: {n_cells} cells\")\n",
    "print(f\"Sampled: {ad_subset.n_obs} cells\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cd0a4f-3cd9-4d2f-b0b9-ce70afd3485f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e8bf6c8-aaac-47a1-bd7e-12b682e72504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class scMeta(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes, heads=4, dropout=0.3):\n",
    "        super(scMeta, self).__init__()\n",
    "\n",
    "        # Transformer layers\n",
    "        self.conv1 = TransformerConv(in_channels=input_dim, out_channels=hidden_dim, heads=heads, dropout=dropout)\n",
    "        self.conv2 = TransformerConv(in_channels=hidden_dim * heads, out_channels=hidden_dim, heads=1, dropout=dropout)\n",
    "\n",
    "        # Classifier head\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            Dropout(dropout),\n",
    "            Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, return_embedding=False):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        if return_embedding:\n",
    "            return logits, x  # logits, embeddings\n",
    "        else:\n",
    "            return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36edb17a-d172-4452-83b3-7f7fbef5c4ab",
   "metadata": {},
   "source": [
    "# Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d47932ff-72d3-4d89-ab0d-7d15863d9848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "if not isinstance(ad_subset.X, np.ndarray):\n",
    "    X = torch.tensor(ad_subset.X.toarray(), dtype=torch.float32)\n",
    "else:\n",
    "    X = torch.tensor(ad_subset.X, dtype=torch.float32)\n",
    "\n",
    "# Graph edges\n",
    "adj = ad_subset.obsp[\"connectivities\"].tocoo()\n",
    "edge_index = torch.tensor(np.vstack((ad_subsetj.row, ad_subsetj.col)), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b7b2fca-5f7c-403a-ba16-db0de42970c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "\n",
    "# cells from patients with no mets\n",
    "primary_mask = (ad_subset.obs[\"source\"] == \"Non_metastatic_local\").values\n",
    "\n",
    "# cells from patients with known mets\n",
    "local_mask = (ad_subset.obs[\"source\"] == \"Metastatic_local\").values\n",
    "\n",
    "# cells from non-primary organs, distant mets\n",
    "distant_mask = (ad_subset.obs[\"source\"] == \"Metastatic_distant\").values\n",
    "\n",
    "# this is for all 3 classes, which are all used during training\n",
    "y_3class = np.full(ad_subset.n_obs, -1, dtype=int)\n",
    "y_3class[primary_mask] = 0\n",
    "y_3class[local_mask] = 1\n",
    "y_3class[distant_mask] = 2\n",
    "y_3class = torch.tensor(y_3class, dtype=torch.long)\n",
    "\n",
    "# Binary label for Non_metastatic_local vs Metastatic_local mets only, used in evaluation\n",
    "y_binary = np.full(ad_subset.n_obs, -1, dtype=int)\n",
    "y_binary[primary_mask] = 0\n",
    "y_binary[local_mask] = 1\n",
    "y_binary = torch.tensor(y_binary, dtype=torch.long)\n",
    "valid_mask = (y_3class == 0) | (y_3class == 1)\n",
    "valid_idx = np.where(valid_mask)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab698b33-b05b-46a4-8df1-9e70fee09ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 72564 nodes\n",
      "Primary: 32880 | Local: 14915 | Distant: 24769\n",
      "67784 training nodes 4780 validation nodes\n"
     ]
    }
   ],
   "source": [
    "# ===== 10% Stratified Split (Primary vs Local only) =====\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "train_valid_idx, heldout_idx = next(split.split(valid_idx, y_3class[valid_idx]))\n",
    "\n",
    "val_idx = valid_idx[heldout_idx]       # final val set = only 0/1 labels\n",
    "train_idx = np.setdiff1d(np.arange(ad_subset.n_obs), val_idx)  # everything else is training\n",
    "\n",
    "\n",
    "data = Data(\n",
    "    x=X,\n",
    "    edge_index=edge_index,\n",
    "    y=y_3class\n",
    ")\n",
    "data.train_idx = train_idx\n",
    "data.val_idx = val_idx\n",
    "data.y_binary = y_binary\n",
    "\n",
    "print(f\"Prepared {data.num_nodes} nodes\")\n",
    "print(f\"Primary: {(y_3class==0).sum().item()} | Local: {(y_3class==1).sum().item()} | Distant: {(y_3class==2).sum().item()}\")\n",
    "print(len(train_idx), 'training nodes', len(val_idx), 'validation nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd0aa72-a8cc-4ea9-a18f-1b56cc81f4b2",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c8b0f9f-7dd7-4f01-90aa-a0a40b868b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x_val, y_val, y_binary, device):\n",
    "    model.eval()\n",
    "\n",
    "    # Self-loop edges only\n",
    "    N = x_val.size(0)\n",
    "    edge_index_val = torch.arange(N, device=device).unsqueeze(0).repeat(2, 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits, _ = model(x_val, edge_index=edge_index_val, return_embedding=True)\n",
    "\n",
    "    y_true_3class = y_val.cpu().numpy()\n",
    "    y_pred_3class = logits.argmax(dim=1).cpu().numpy()\n",
    "    y_prob_3class = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "    \n",
    "    y_binary = y_binary.to(device)\n",
    "    y_val = y_val.to(device)\n",
    "\n",
    "\n",
    "    # Filter for binary classification (primary vs local mets)\n",
    "    binary_mask = (y_binary != -1) & (y_val != 2)  # exclude distant mets\n",
    "    \n",
    "    y_true_bin = y_binary[binary_mask].cpu().numpy()\n",
    "    y_pred_bin = logits.argmax(dim=1)[binary_mask].cpu().numpy()\n",
    "    y_prob_bin = torch.softmax(logits, dim=1)[binary_mask, :2].cpu().numpy()\n",
    "    \n",
    "    # Compute metrics\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true_bin, y_prob_bin[:, 1], multi_class='ovr', average='weighted')\n",
    "    except:\n",
    "        auc = np.nan\n",
    "\n",
    "    try:\n",
    "        auprc = average_precision_score(y_true_bin, y_prob_bin[:, 1], average='weighted')\n",
    "    except:\n",
    "        auprc = np.nan\n",
    "\n",
    "    acc = accuracy_score(y_true_bin, y_pred_bin)\n",
    "    f1 = f1_score(y_true_bin, y_pred_bin, average='weighted')\n",
    "    \n",
    "    return acc, f1, auc, auprc, y_true_bin, y_pred_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffbeaa8f-bd7f-4a5e-93aa-a4256a6937d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrast loss\n",
    "def NT_Xent(embeddings, tau=0.5):\n",
    "    device = embeddings.device\n",
    "    z_i = F.normalize(embeddings, dim=1)\n",
    "    z_j = F.normalize(embeddings[torch.randperm(z_i.size(0))], dim=1)\n",
    "\n",
    "    logits = torch.mm(z_i, z_j.t()) / tau\n",
    "    labels = torch.arange(z_i.size(0), device=device)\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f002fc66-88c4-4b38-a861-7ff18eb6f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(data, save_dir, epochs=100, seed=42, patience=10, gamma=0.1):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    memory_usgae()\n",
    "\n",
    "    train_idx = data.train_idx\n",
    "    val_idx = data.val_idx\n",
    "\n",
    "    train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    train_mask[train_idx] = True\n",
    "\n",
    "    # Build train graph\n",
    "    edge_index_train, _ = subgraph(train_mask, data.edge_index, relabel_nodes=True)\n",
    "    x_train = data.x[train_mask]\n",
    "    y_train = data.y[train_mask]\n",
    "\n",
    "    train_data = Data(\n",
    "        x=x_train,\n",
    "        edge_index=edge_index_train,\n",
    "        y=y_train\n",
    "    )\n",
    "\n",
    "    x_val = data.x[val_idx].to(device)\n",
    "    y_val = data.y[val_idx].to(device)\n",
    "\n",
    "    y_binary_val = data.y_binary[val_idx]\n",
    "\n",
    "\n",
    "    model = scMeta(\n",
    "        input_dim=data.num_node_features,\n",
    "        hidden_dim=128,\n",
    "        num_classes=len(torch.unique(data.y))\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    best_acc = 0\n",
    "    best_auc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_model_path = os.path.join(save_dir, f\"best_model.pt\")\n",
    "\n",
    "    # double check class distribution in val set\n",
    "    # no distant mets should be here, no label 2\n",
    "    y_val_counts = torch.bincount(data.y[val_idx])\n",
    "    for label, count in enumerate(y_val_counts):\n",
    "        print(f\"Val label {label}: {count.item()} samples\")\n",
    "\n",
    "    # Pre-training eval\n",
    "    acc, f1, auc, auprc, _, _ = evaluate(\n",
    "        model, x_val, y_val, y_binary_val, device\n",
    "    )\n",
    "    print(f\"Pre-training stats: Acc={acc:.4f}, F1={f1:.4f}, AUROC={auc:.4f}, AUPRC={auprc:.4f}\")\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        loader = RandomNodeLoader(train_data, num_parts=100, shuffle=True)\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            logits, emb = model(batch.x, batch.edge_index, return_embedding=True)\n",
    "\n",
    "            loss_ce = F.cross_entropy(logits, batch.y)\n",
    "            loss_con = NT_Xent(emb, tau=0.5)\n",
    "            loss = loss_ce + gamma * loss_con\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Evaluate\n",
    "        acc, f1, auc, auprc, _, _ = evaluate(\n",
    "            model, x_val, y_val, y_binary_val, device\n",
    "        )\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}: Acc={acc:.4f}, F1={f1:.4f}, AUROC={auc:.4f}, AUPRC={auprc:.4f}\")\n",
    "\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "361347e7-42e3-46e1-bf9c-471202031943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 23.45 GB\n",
      "Val label 0: 3288 samples\n",
      "Val label 1: 1492 samples\n",
      "Pre-training stats: Acc=0.0274, F1=0.0466, AUROC=0.5672, AUPRC=0.3736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:00<02:14,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Acc=0.5278, F1=0.5973, AUROC=0.8214, AUPRC=0.6450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:07<02:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Acc=0.8427, F1=0.8785, AUROC=0.9419, AUPRC=0.8735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [00:13<01:52,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Acc=0.7257, F1=0.8076, AUROC=0.9183, AUPRC=0.8346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [00:19<01:45,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Acc=0.8033, F1=0.8569, AUROC=0.9410, AUPRC=0.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [00:25<01:40,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Acc=0.7132, F1=0.8005, AUROC=0.8815, AUPRC=0.7775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [00:32<01:33,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Acc=0.8123, F1=0.8647, AUROC=0.9338, AUPRC=0.8621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 58/200 [00:37<01:31,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/scratch/gilbreth/wang3712/Metastasis_single_cell/scMeta_example/'\n",
    "\n",
    "run_model(\n",
    "    data,\n",
    "    save_dir=save_dir,\n",
    "    epochs=200,\n",
    "    patience=20,\n",
    "    gamma=4.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07effc9c-0bfe-4040-ad7f-6beb2530063a",
   "metadata": {},
   "source": [
    "# Downstream Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d088396d-4e37-4c1e-a07f-35db6163e878",
   "metadata": {},
   "source": [
    "Please refer https://github.com/loooooooopi/scMeta/blob/master/Reproducibility/scMeta_downstream_analysis.ipynb for visualization of latent embeddings genereated by the transformer, feature(gene) priorization and pathway analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a2869-7f7d-47be-a815-a2026534c412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gears",
   "language": "python",
   "name": "gears"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
